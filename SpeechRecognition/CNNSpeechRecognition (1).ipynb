{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "import tensorflow_hub as hub\n",
    "%matplotlib inline\n",
    "\n",
    "L = 16000\n",
    "legal_labels = 'silence bed bird cat dog down eight five four go happy house left marvin nine no off on one right seven sheila six stop three tree two up wow yes zero'.split()\n",
    "#legal_labels = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "#src folders\n",
    "root_path = './mfcc'\n",
    "out_path = r'.'\n",
    "model_path = r'.'\n",
    "train_data_path = os.path.join(root_path, 'train')\n",
    "test_data_path = os.path.join(root_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_wavs_fname(dirpath, ext='png'):\n",
    "    print(dirpath)\n",
    "    fpaths = glob(os.path.join(dirpath, r'*/*' + ext))\n",
    "    pat = r'.+/(\\w+)/\\w+\\.' + ext + '$'\n",
    "    labels = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            labels.append(r.group(1))\n",
    "    pat = r'.+/(\\w+\\.' + ext + ')$'\n",
    "    fnames = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            fnames.append(r.group(1))\n",
    "    return labels, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_transform(labels):\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == '_background_noise_':\n",
    "            nlabels.append('silence')\n",
    "        elif label not in legal_labels:\n",
    "            nlabels.append('unknown')\n",
    "        else:\n",
    "            nlabels.append(label)\n",
    "    return pd.Series(nlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./mfcc/train\n"
     ]
    }
   ],
   "source": [
    "labels, fnames = list_wavs_fname(train_data_path)\n",
    "# print(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[140 144  32]\n",
      "   [140 144  32]\n",
      "   [140 144  32]\n",
      "   ...\n",
      "   [142 125  39]\n",
      "   [142 125  39]\n",
      "   [142 125  39]]\n",
      "\n",
      "  [[140 144  32]\n",
      "   [140 144  32]\n",
      "   [140 144  32]\n",
      "   ...\n",
      "   [142 125  39]\n",
      "   [142 125  39]\n",
      "   [142 125  39]]\n",
      "\n",
      "  [[140 145  32]\n",
      "   [140 145  32]\n",
      "   [140 145  32]\n",
      "   ...\n",
      "   [141 131  37]\n",
      "   [141 131  37]\n",
      "   [141 131  37]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[138 153  30]\n",
      "   [138 153  30]\n",
      "   [138 153  30]\n",
      "   ...\n",
      "   [139 147  31]\n",
      "   [139 147  31]\n",
      "   [139 147  31]]\n",
      "\n",
      "  [[138 153  30]\n",
      "   [138 153  30]\n",
      "   [138 153  30]\n",
      "   ...\n",
      "   [138 153  30]\n",
      "   [138 153  30]\n",
      "   [138 153  30]]\n",
      "\n",
      "  [[138 153  30]\n",
      "   [138 153  30]\n",
      "   [138 153  30]\n",
      "   ...\n",
      "   [136 157  30]\n",
      "   [136 157  30]\n",
      "   [136 157  30]]]\n",
      "\n",
      "\n",
      " [[[141 139  34]\n",
      "   [141 139  34]\n",
      "   [141 139  34]\n",
      "   ...\n",
      "   [133 166  33]\n",
      "   [133 166  33]\n",
      "   [133 166  33]]\n",
      "\n",
      "  [[141 139  34]\n",
      "   [141 139  34]\n",
      "   [141 139  34]\n",
      "   ...\n",
      "   [133 166  33]\n",
      "   [133 166  33]\n",
      "   [133 166  33]]\n",
      "\n",
      "  [[141 138  34]\n",
      "   [141 138  34]\n",
      "   [141 138  34]\n",
      "   ...\n",
      "   [141 131  37]\n",
      "   [141 131  37]\n",
      "   [141 131  37]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[141 137  34]\n",
      "   [141 137  34]\n",
      "   [141 137  34]\n",
      "   ...\n",
      "   [141 138  34]\n",
      "   [141 138  34]\n",
      "   [141 138  34]]\n",
      "\n",
      "  [[141 137  34]\n",
      "   [141 137  34]\n",
      "   [141 137  34]\n",
      "   ...\n",
      "   [141 132  36]\n",
      "   [141 132  36]\n",
      "   [141 132  36]]\n",
      "\n",
      "  [[141 138  34]\n",
      "   [141 138  34]\n",
      "   [141 138  34]\n",
      "   ...\n",
      "   [141 132  36]\n",
      "   [141 132  36]\n",
      "   [141 132  36]]]\n",
      "\n",
      "\n",
      " [[[118  38  71]\n",
      "   [118  38  71]\n",
      "   [118  38  71]\n",
      "   ...\n",
      "   [ 91 204 105]\n",
      "   [ 91 204 105]\n",
      "   [ 91 204 105]]\n",
      "\n",
      "  [[118  38  71]\n",
      "   [118  38  71]\n",
      "   [118  38  71]\n",
      "   ...\n",
      "   [ 91 204 105]\n",
      "   [ 91 204 105]\n",
      "   [ 91 204 105]]\n",
      "\n",
      "  [[141 137  34]\n",
      "   [141 137  34]\n",
      "   [141 137  34]\n",
      "   ...\n",
      "   [141 137  34]\n",
      "   [141 137  34]\n",
      "   [141 137  34]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[130 170  36]\n",
      "   [130 170  36]\n",
      "   [130 170  36]\n",
      "   ...\n",
      "   [125 177  44]\n",
      "   [125 177  44]\n",
      "   [125 177  44]]\n",
      "\n",
      "  [[128 173  39]\n",
      "   [128 173  39]\n",
      "   [128 173  39]\n",
      "   ...\n",
      "   [130 169  35]\n",
      "   [130 169  35]\n",
      "   [130 169  35]]\n",
      "\n",
      "  [[133 165  32]\n",
      "   [133 165  32]\n",
      "   [133 165  32]\n",
      "   ...\n",
      "   [129 172  38]\n",
      "   [129 172  38]\n",
      "   [129 172  38]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[140 146  31]\n",
      "   [140 146  31]\n",
      "   [140 146  31]\n",
      "   ...\n",
      "   [113 190  66]\n",
      "   [113 190  66]\n",
      "   [113 190  66]]\n",
      "\n",
      "  [[140 146  31]\n",
      "   [140 146  31]\n",
      "   [140 146  31]\n",
      "   ...\n",
      "   [113 190  66]\n",
      "   [113 190  66]\n",
      "   [113 190  66]]\n",
      "\n",
      "  [[126 176  42]\n",
      "   [126 176  42]\n",
      "   [126 176  42]\n",
      "   ...\n",
      "   [125 177  43]\n",
      "   [125 177  43]\n",
      "   [125 177  43]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[127 175  41]\n",
      "   [127 175  41]\n",
      "   [127 175  41]\n",
      "   ...\n",
      "   [126 176  42]\n",
      "   [126 176  42]\n",
      "   [126 176  42]]\n",
      "\n",
      "  [[121 182  51]\n",
      "   [121 182  51]\n",
      "   [121 182  51]\n",
      "   ...\n",
      "   [128 173  39]\n",
      "   [128 173  39]\n",
      "   [128 173  39]]\n",
      "\n",
      "  [[126 176  42]\n",
      "   [126 176  42]\n",
      "   [126 176  42]\n",
      "   ...\n",
      "   [123 179  47]\n",
      "   [123 179  47]\n",
      "   [123 179  47]]]\n",
      "\n",
      "\n",
      " [[[139 148  31]\n",
      "   [139 148  31]\n",
      "   [139 148  31]\n",
      "   ...\n",
      "   [142 111  45]\n",
      "   [142 111  45]\n",
      "   [142 111  45]]\n",
      "\n",
      "  [[139 148  31]\n",
      "   [139 148  31]\n",
      "   [139 148  31]\n",
      "   ...\n",
      "   [142 111  45]\n",
      "   [142 111  45]\n",
      "   [142 111  45]]\n",
      "\n",
      "  [[140 144  32]\n",
      "   [140 144  32]\n",
      "   [140 144  32]\n",
      "   ...\n",
      "   [138 153  30]\n",
      "   [138 153  30]\n",
      "   [138 153  30]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[140 146  31]\n",
      "   [140 146  31]\n",
      "   [140 146  31]\n",
      "   ...\n",
      "   [140 146  31]\n",
      "   [140 146  31]\n",
      "   [140 146  31]]\n",
      "\n",
      "  [[140 145  32]\n",
      "   [140 145  32]\n",
      "   [140 145  32]\n",
      "   ...\n",
      "   [138 153  30]\n",
      "   [138 153  30]\n",
      "   [138 153  30]]\n",
      "\n",
      "  [[140 145  32]\n",
      "   [140 145  32]\n",
      "   [140 145  32]\n",
      "   ...\n",
      "   [139 148  31]\n",
      "   [139 148  31]\n",
      "   [139 148  31]]]\n",
      "\n",
      "\n",
      " [[[102 198  85]\n",
      "   [102 198  85]\n",
      "   [102 198  85]\n",
      "   ...\n",
      "   [ 82 208 119]\n",
      "   [ 82 208 119]\n",
      "   [ 82 208 119]]\n",
      "\n",
      "  [[102 198  85]\n",
      "   [102 198  85]\n",
      "   [102 198  85]\n",
      "   ...\n",
      "   [ 82 208 119]\n",
      "   [ 82 208 119]\n",
      "   [ 82 208 119]]\n",
      "\n",
      "  [[ 63 215 149]\n",
      "   [ 63 215 149]\n",
      "   [ 63 215 149]\n",
      "   ...\n",
      "   [136 159  30]\n",
      "   [136 159  30]\n",
      "   [136 159  30]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[121 182  51]\n",
      "   [121 182  51]\n",
      "   [121 182  51]\n",
      "   ...\n",
      "   [118 185  57]\n",
      "   [118 185  57]\n",
      "   [118 185  57]]\n",
      "\n",
      "  [[112 190  68]\n",
      "   [112 190  68]\n",
      "   [112 190  68]\n",
      "   ...\n",
      "   [119 184  54]\n",
      "   [119 184  54]\n",
      "   [119 184  54]]\n",
      "\n",
      "  [[125 177  44]\n",
      "   [125 177  44]\n",
      "   [125 177  44]\n",
      "   ...\n",
      "   [118 185  57]\n",
      "   [118 185  57]\n",
      "   [118 185  57]]]]\n"
     ]
    }
   ],
   "source": [
    "new_sample_rate = 8000\n",
    "y_train = []\n",
    "x_train = []\n",
    "# a = cv2.imread(os.path.join(train_data_path, labels[0], fnames[0]))\n",
    "\n",
    "for label, fname in zip(labels, fnames):\n",
    "        x_train.append(cv2.resize(cv2.imread(os.path.join(train_data_path, label, fname)), dsize=(28,28), interpolation=cv2.INTER_NEAREST))\n",
    "        y_train.append(label)\n",
    "x_train = np.array(x_train)\n",
    "y_train = label_transform(y_train)\n",
    "# label_index = y_train.columns.values\n",
    "# y_train = y_train.values\n",
    "# y_train = np.array(y_train)\n",
    "del labels, fnames\n",
    "gc.collect()\n",
    "print(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat': 3, 'six': 22, 'nine': 14, 'tree': 25, 'right': 19, 'house': 11, 'four': 8, 'two': 26, 'stop': 23, 'go': 9, 'zero': 30, 'seven': 20, 'bed': 1, 'left': 12, 'one': 18, 'silence': 0, 'sheila': 21, 'no': 15, 'up': 27, 'down': 5, 'happy': 10, 'bird': 2, 'yes': 29, 'three': 24, 'eight': 6, 'on': 17, 'off': 16, 'dog': 4, 'marvin': 13, 'wow': 28, 'five': 7}\n"
     ]
    }
   ],
   "source": [
    "labels_dict = {}\n",
    "i = 0\n",
    "for k in legal_labels:\n",
    "    if k == '_background_noise_':\n",
    "        k = 'silence'\n",
    "    labels_dict[k] = i\n",
    "    i += 1\n",
    "print(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        tree\n",
      "1        tree\n",
      "2        tree\n",
      "3        tree\n",
      "4        tree\n",
      "5        tree\n",
      "6        tree\n",
      "7        tree\n",
      "8        tree\n",
      "9        tree\n",
      "10       tree\n",
      "11       tree\n",
      "12       tree\n",
      "13       tree\n",
      "14       tree\n",
      "15       tree\n",
      "16       tree\n",
      "17       tree\n",
      "18       tree\n",
      "19       tree\n",
      "20       tree\n",
      "21       tree\n",
      "22       tree\n",
      "23       tree\n",
      "24       tree\n",
      "25       tree\n",
      "26       tree\n",
      "27       tree\n",
      "28       tree\n",
      "29       tree\n",
      "         ... \n",
      "64793     six\n",
      "64794     six\n",
      "64795     six\n",
      "64796     six\n",
      "64797     six\n",
      "64798     six\n",
      "64799     six\n",
      "64800     six\n",
      "64801     six\n",
      "64802     six\n",
      "64803     six\n",
      "64804     six\n",
      "64805     six\n",
      "64806     six\n",
      "64807     six\n",
      "64808     six\n",
      "64809     six\n",
      "64810     six\n",
      "64811     six\n",
      "64812     six\n",
      "64813     six\n",
      "64814     six\n",
      "64815     six\n",
      "64816     six\n",
      "64817     six\n",
      "64818     six\n",
      "64819     six\n",
      "64820     six\n",
      "64821     six\n",
      "64822     six\n",
      "Length: 64823, dtype: object\n",
      "[25 25 25 ... 22 22 22]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "#labels_dict = {\"yes\":0, \"no\":1, \"up\":2, \"down\":3, \"left\":4, \"right\":5, \"on\":6, \"off\":7, \"stop\":8, \"go\":9, \"silence\":10, \"unknown\":11}\n",
    "for i, elem in enumerate(y_train):\n",
    "    y_train[i] = labels_dict[y_train[i]]\n",
    "y_train = np.array(y_train).astype(int)\n",
    "print(y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23    2380\n",
       "29    2377\n",
       "20    2377\n",
       "30    2376\n",
       "15    2375\n",
       "27    2375\n",
       "26    2373\n",
       "8     2372\n",
       "9     2372\n",
       "18    2370\n",
       "22    2369\n",
       "19    2367\n",
       "17    2367\n",
       "14    2364\n",
       "5     2359\n",
       "16    2357\n",
       "7     2357\n",
       "24    2356\n",
       "12    2353\n",
       "6     2352\n",
       "11    1750\n",
       "13    1746\n",
       "4     1746\n",
       "28    1745\n",
       "10    1742\n",
       "21    1734\n",
       "3     1733\n",
       "25    1733\n",
       "2     1731\n",
       "1     1713\n",
       "0      102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.Series(y_train)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the data\n",
    "s = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(s)\n",
    "x_train = x_train[s]\n",
    "y_train = y_train[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 3)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "train_data = x_train[:50000,:]\n",
    "train_labels = y_train[:50000]\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14823, 28, 28, 3)\n",
      "(14823,)\n",
      "29    575\n",
      "15    571\n",
      "8     566\n",
      "12    559\n",
      "7     557\n",
      "26    553\n",
      "30    552\n",
      "24    548\n",
      "23    547\n",
      "14    544\n",
      "16    541\n",
      "22    538\n",
      "17    538\n",
      "5     536\n",
      "20    532\n",
      "19    528\n",
      "27    523\n",
      "6     521\n",
      "18    517\n",
      "9     508\n",
      "3     406\n",
      "2     405\n",
      "28    405\n",
      "11    399\n",
      "10    396\n",
      "21    396\n",
      "4     394\n",
      "1     386\n",
      "13    385\n",
      "25    373\n",
      "0      24\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "eval_data = x_train[-14823:,:]\n",
    "eval_labels = y_train[-14823:]\n",
    "print(eval_data.shape)\n",
    "print(eval_labels.shape)\n",
    "print(pd.Series(eval_labels).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data.flatten()\n",
    "# eval_data = eval_data.flatten()\n",
    "# print(eval_data.shape)\n",
    "# print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.astype('float32')\n",
    "eval_data = eval_data.astype('float32')\n",
    "train_data = np.multiply(train_data, 1.0/255.0)\n",
    "eval_data = np.multiply(eval_data, 1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 200\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 31 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.25 # Dropout, probability to drop a unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural network\n",
    "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # TF Estimator input is a dict, in case of multiple inputs\n",
    "        x = x_dict['images']\n",
    "\n",
    "        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "        # Reshape to match picture format [Height x Width x Channel]\n",
    "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "        x = tf.reshape(x, shape=[-1, 28, 28, 3])\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "\n",
    "        # Convolution Layer with 64 filters and a kernel size of 3\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    # Because Dropout have different behavior at training and prediction time, we\n",
    "    # need to create 2 distinct computation graphs that still share the same weights.\n",
    "    logits_train = conv_net(features, num_classes, dropout, reuse=False,\n",
    "                            is_training=True)\n",
    "    logits_test = conv_net(features, num_classes, dropout, reuse=True,\n",
    "                           is_training=False)\n",
    "\n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "\n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op,\n",
    "                                  global_step=tf.train.get_global_step())\n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn_classification_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    eval_data,\n",
    "    eval_labels):\n",
    "\n",
    "        # Build the Estimator\n",
    "    model = tf.estimator.Estimator(model_fn, model_dir=\"./Savemodel\")\n",
    "\n",
    "    # Define the input function for training\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={'images': train_data}, y=train_labels,\n",
    "        batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "\n",
    "    # Define the input function for evaluating\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={'images': eval_data}, y=eval_labels,\n",
    "        batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = {'images': train_data},\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "\n",
    "    predict_eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = {'images': eval_data},\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "    # Create feature columns.\n",
    "    feature_columns = [tf.feature_column.numeric_column('pixels', shape=784)]\n",
    "\n",
    "    # Train the model, but do so inside a loop so that we can periodically assess\n",
    "    # loss metrics.\n",
    "    periods = 10\n",
    "    print(\"Training model...\")\n",
    "    print(\"LogLoss error (on validation data):\")\n",
    "    training_errors = []\n",
    "    validation_errors = []\n",
    "    for period in range (0, periods):\n",
    "        # Train the model, starting from the prior state.\n",
    "        model.train(input_fn, steps=steps)\n",
    "\n",
    "        train_pred = model.predict(predict_input_fn)\n",
    "        eval_pred = model.predict(predict_eval_input_fn)\n",
    "        train_pred = np.array([item for item in train_pred])\n",
    "        eval_pred  = np.array([item for item in eval_pred])\n",
    "\n",
    "\n",
    "        training_pred_one_hot = tf.keras.utils.to_categorical(train_pred,31)\n",
    "        validation_pred_one_hot = tf.keras.utils.to_categorical(eval_pred,31)    \n",
    "\n",
    "        training_log_loss = metrics.log_loss(train_labels, training_pred_one_hot)\n",
    "        validation_log_loss = metrics.log_loss(eval_labels, validation_pred_one_hot)\n",
    "        # Occasionally print the current loss.\n",
    "        print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
    "        # Add the loss metrics from this period to our list.\n",
    "        training_errors.append(training_log_loss)\n",
    "        validation_errors.append(validation_log_loss)\n",
    "\n",
    "    print(\"Model training finished.\")\n",
    "    # Calculate final predictions (not probabilities, as above).\n",
    "    final_predictions = model.predict(input_fn=predict_eval_input_fn)\n",
    "    final_predictions = np.array([item for item in final_predictions])\n",
    "\n",
    "\n",
    "    accuracy = metrics.accuracy_score(eval_labels, final_predictions)\n",
    "    print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
    "\n",
    "    # Output a graph of loss metrics over periods.\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"LogLoss vs. Periods\")\n",
    "    plt.plot(training_errors, label=\"training\")\n",
    "    plt.plot(validation_errors, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_train_distribute': None, '_tf_random_seed': None, '_task_type': 'worker', '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_global_id_in_cluster': 0, '_model_dir': './Savemodel', '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_task_id': 0, '_is_chief': True, '_session_config': None, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff10ab02668>, '_num_worker_replicas': 1}\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 3.4586868\n",
      "INFO:tensorflow:global_step/sec: 10.0895\n",
      "INFO:tensorflow:step = 101, loss = 3.0038226 (9.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0907\n",
      "INFO:tensorflow:step = 201, loss = 2.5439146 (9.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.93943\n",
      "INFO:tensorflow:step = 301, loss = 1.9943248 (10.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.89509\n",
      "INFO:tensorflow:step = 401, loss = 1.5439814 (10.106 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.3339505.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 00 : 14.41\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 501 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:step = 501, loss = 1.6668305\n",
      "INFO:tensorflow:global_step/sec: 9.87534\n",
      "INFO:tensorflow:step = 601, loss = 1.2591861 (10.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.88167\n",
      "INFO:tensorflow:step = 701, loss = 1.1251247 (10.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.81479\n",
      "INFO:tensorflow:step = 801, loss = 1.2175312 (10.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.89724\n",
      "INFO:tensorflow:step = 901, loss = 1.3035544 (10.104 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.0465965.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 01 : 10.13\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:step = 1001, loss = 0.90883225\n",
      "INFO:tensorflow:global_step/sec: 9.91246\n",
      "INFO:tensorflow:step = 1101, loss = 1.0093529 (10.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0389\n",
      "INFO:tensorflow:step = 1201, loss = 1.1250014 (9.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.52271\n",
      "INFO:tensorflow:step = 1301, loss = 1.0155773 (10.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.82411\n",
      "INFO:tensorflow:step = 1401, loss = 1.2466668 (10.179 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.9978133.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-1500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-1500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 02 : 8.83\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-1500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1501 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:step = 1501, loss = 0.7379432\n",
      "INFO:tensorflow:global_step/sec: 10.0381\n",
      "INFO:tensorflow:step = 1601, loss = 1.13316 (9.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.86553\n",
      "INFO:tensorflow:step = 1701, loss = 1.0168624 (10.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.7751\n",
      "INFO:tensorflow:step = 1801, loss = 0.8853788 (10.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.92138\n",
      "INFO:tensorflow:step = 1901, loss = 0.5301808 (10.079 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.90775794.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 03 : 8.36\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:step = 2001, loss = 0.72736204\n",
      "INFO:tensorflow:global_step/sec: 9.79634\n",
      "INFO:tensorflow:step = 2101, loss = 0.76385087 (10.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.92776\n",
      "INFO:tensorflow:step = 2201, loss = 0.6921345 (10.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.97467\n",
      "INFO:tensorflow:step = 2301, loss = 0.65732825 (10.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0296\n",
      "INFO:tensorflow:step = 2401, loss = 0.8953441 (9.971 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.9667345.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-2500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-2500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 04 : 7.85\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-2500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2501 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:step = 2501, loss = 0.726248\n",
      "INFO:tensorflow:global_step/sec: 9.74535\n",
      "INFO:tensorflow:step = 2601, loss = 0.702682 (10.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.884\n",
      "INFO:tensorflow:step = 2701, loss = 0.6340303 (10.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.93211\n",
      "INFO:tensorflow:step = 2801, loss = 0.8306999 (10.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.99308\n",
      "INFO:tensorflow:step = 2901, loss = 0.73387307 (10.007 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.63999385.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 05 : 7.90\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3001 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:step = 3001, loss = 0.7197732\n",
      "INFO:tensorflow:global_step/sec: 9.97726\n",
      "INFO:tensorflow:step = 3101, loss = 0.613914 (10.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.86221\n",
      "INFO:tensorflow:step = 3201, loss = 0.5560927 (10.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.92473\n",
      "INFO:tensorflow:step = 3301, loss = 0.50650173 (10.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.87091\n",
      "INFO:tensorflow:step = 3401, loss = 0.9089103 (10.130 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3500 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.57901.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-3500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-3500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 06 : 7.49\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-3500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3501 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:step = 3501, loss = 0.6398756\n",
      "INFO:tensorflow:global_step/sec: 9.87377\n",
      "INFO:tensorflow:step = 3601, loss = 0.7038942 (10.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0464\n",
      "INFO:tensorflow:step = 3701, loss = 0.6779783 (9.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.67834\n",
      "INFO:tensorflow:step = 3801, loss = 0.64502937 (10.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.74538\n",
      "INFO:tensorflow:step = 3901, loss = 0.6847953 (10.261 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.6087326.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 07 : 7.28\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:step = 4001, loss = 0.8759709\n",
      "INFO:tensorflow:global_step/sec: 9.84754\n",
      "INFO:tensorflow:step = 4101, loss = 0.81064415 (10.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.71842\n",
      "INFO:tensorflow:step = 4201, loss = 0.5994972 (10.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.84267\n",
      "INFO:tensorflow:step = 4301, loss = 0.53559047 (10.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.82899\n",
      "INFO:tensorflow:step = 4401, loss = 0.4279462 (10.174 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4500 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.60338396.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-4500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-4500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 08 : 7.68\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-4500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 4501 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:step = 4501, loss = 0.38359016\n",
      "INFO:tensorflow:global_step/sec: 9.78762\n",
      "INFO:tensorflow:step = 4601, loss = 0.47279233 (10.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0305\n",
      "INFO:tensorflow:step = 4701, loss = 0.4907514 (9.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.95826\n",
      "INFO:tensorflow:step = 4801, loss = 0.53060263 (10.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0657\n",
      "INFO:tensorflow:step = 4901, loss = 0.6476734 (9.935 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into ./Savemodel/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.69898885.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 09 : 6.95\n",
      "Model training finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Savemodel/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Final accuracy (on validation data): 0.80\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = train_cnn_classification_model(\n",
    "    learning_rate=.001,\n",
    "    steps=500,\n",
    "    batch_size=1000,\n",
    "    train_data=train_data,\n",
    "    train_labels=train_labels,\n",
    "    eval_data=eval_data,\n",
    "    eval_labels=eval_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data, sample_labels = parse_labels_and_features(df_sample)\n",
    "sample_labels = np.asarray(sample_labels, dtype=np.int32)\n",
    "df_test = np.asarray(df_test, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-498-c8016718a6e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Define the input function for evaluating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m test_input_fn = tf.estimator.inputs.numpy_input_fn(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "model = train_cnn_classification_model\n",
    "\n",
    "# Define the input function for evaluating\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {'images': df_test},\n",
    "    y=sample_labels,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_predictions = model.predict(test_input_fn)\n",
    "test_predictions = np.array([item for item in test_predictions])\n",
    "\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'ImageId': df_sample.ImageId, 'Label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission6.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
